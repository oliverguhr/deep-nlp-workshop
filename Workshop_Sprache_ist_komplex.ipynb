{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "colab": {
      "name": "Workshop Sprache ist komplex.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oliverguhr/deep-nlp-workshop/blob/main/Workshop_Sprache_ist_komplex.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGtaNV7xw-0V"
      },
      "source": [
        "# Gut oder schlecht? Ein simples Machine-Learning-Szenario.\n",
        "\n",
        "Jeden Tag schrieben hunderte Kunden ihre Meinung zu unseren Produkten. Dabei den Überblick \n",
        "zu behalten, ist nicht einfach. Wir möchten daher ein kleines Programm schreiben, welches feststellt ob die \n",
        "Kunden positiv oder eher negativ über unsere Produkte sprechen.\n",
        "\n",
        "Dazu bekommen wir eine Liste der Kundenmeinungen. Wir sollen ein kleines Prgramm schreiben, welches eine \n",
        "Eins zurückgibt wenn eine Kundenaussage positiv ist und eine Null zurück gibt, wenn eine Kundenaussage \n",
        "negativ ist. Auf diese Weise können wir am Schluss einfach auszählen wieviel Prozent der Kunden postiv über unsere Produkte sprechen."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0ajQU47w-0V"
      },
      "source": [
        "#Empirische Daten sind \"messy\".\n",
        "\n",
        "feedback_texte = [\"Das ist ein tolles Produkt.\",\n",
        "                  \"Ich bin super zufrieden!\",\n",
        "                  \"Funktioniert nur sehr schlecht.\",\n",
        "                  \"Ist mir viel zu teuer.\",                                    \n",
        "                  \"Super Produkt, toller service\",\n",
        "                  \"Für die Leistung zu teuer.\",\n",
        "                  \"Ein ein super Produkt.\" #Tippfehler\n",
        "                  \"Super Preis, für die Leistung\", #uneindeutige Aussage\n",
        "                  \"Hab eins für meine Oma gekauft und die ist sehr zufrieden\",\n",
        "                  \"Kunderservice ist ein nur toll.\"] #auch hier eine uneindeutige Aussage"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_e5Hfx2w-0V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ea7469d-7ffe-4725-ecd2-e46ceba7d9f0"
      },
      "source": [
        "#Overfitting: Wenn wir unser Modell nur auf Grundlage obiger Daten bauen, könnten wir auf die Idee kommen, dass eine\n",
        "#triviale Lösung gut genug ist. Für zuverlässig funktionierende Modelle brauchen wir ausreichende - und ausreichend\n",
        "#diverse - Trainingsdaten. Andernfalls \"overfitten\" wir unser Modell auf eine nicht-repräsentative Teilmenge der Daten.\n",
        "\n",
        "#Triviale Lösung: Unser Kunden-Feedback ist immer super.\n",
        "def sentiment(text):\n",
        "    return 1\n",
        "\n",
        "for text in feedback_texte:\n",
        "    print(f\"{sentiment(text)} = {text}\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 = Das ist ein tolles Produkt.\n",
            "1 = Ich bin super zufrieden!\n",
            "1 = Funktioniert nur sehr schlecht.\n",
            "1 = Ist mir viel zu teuer.\n",
            "1 = Super Produkt, toller service\n",
            "1 = Für die Leistung zu teuer.\n",
            "1 = Ein ein super Produkt.Super Preis, für die Leistung\n",
            "1 = Hab eins für meine Oma gekauft und die ist sehr zufrieden\n",
            "1 = Kunderservice ist ein nur toll.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xg6xMUtNw-0V"
      },
      "source": [
        "## Mehr Texte\n",
        "\n",
        "Da unser System so gut funktioniert, bitten uns die Kollegen weitere Texte zu analysieren:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Z5dHHzCw-0V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42180fd8-e673-4a2f-b462-77cc09a03373"
      },
      "source": [
        "#Vielleicht ist die triviale Lösung doch nicht so gut.\n",
        "feedback_texte_advanced = [\"Das ist ein dolles Produkt.\", #Umgangssprache\n",
        "                  \"Macht meistens was es soll.\", #uneindeutig\n",
        "                  \"Das Produkt ist gar nicht so toll wie ich gedacht hatte.\", #uneindeutig\n",
        "                  \"super, schon nach ZWEI tagen kaputt!!!\", #aussagekräftige Typographie                                    \n",
        "                  \"Bester Service der Welt. Nicht.\", #Satzübergreifende Semantik\n",
        "                  \"Gute Leistung, der Preis ist aber nicht angemessen.\",\n",
        "                  \"Gar nicht mal so gut.\", #uneindeutig\n",
        "                  \"Super Preis, mieser Service.\",\n",
        "                  \":(\", #Sonderzeichen\n",
        "                  \"1 nices teil\"] #Umgangssprache\n",
        "\n",
        "for text in feedback_texte_advanced:\n",
        "    print(f\"{sentiment(text)} = {text}\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 = Das ist ein dolles Produkt.\n",
            "1 = Macht meistens was es soll.\n",
            "1 = Das Produkt ist gar nicht so toll wie ich gedacht hatte.\n",
            "1 = super, schon nach ZWEI tagen kaputt!!!\n",
            "1 = Bester Service der Welt. Nicht.\n",
            "1 = Gute Leistung, der Preis ist aber nicht angemessen.\n",
            "1 = Gar nicht mal so gut.\n",
            "1 = Super Preis, mieser Service.\n",
            "1 = :(\n",
            "1 = 1 nices teil\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "enh9bYkDw-0V"
      },
      "source": [
        "## Machine Learning\n",
        "\n",
        "Wir machen eine ganz einfache BOW-NB-Klassifikation.\n",
        "(BOW - bag of words: wir klassifizieren die Texte anhand ihres Vokabulars, ignorieren aber die Reihenfolge der Wörter;\n",
        "NB - Naive Bayes: eine simple, probabilistische Klassifikation)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzIZTPyIw-0V"
      },
      "source": [
        "#scikit-learn ist eine gut entwickelte Statistik- und ML-Bibliothek für Python\n",
        "#Wir nutzen den TfidfVectorizer für die \"feature extraction\", also um den Text in eine ML-fähige Repräsentation zu bringen.\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer \n",
        "#Das ist unser Klassifikationsalgorithmus\n",
        "from sklearn.naive_bayes import MultinomialNB"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTuIVU-hw-0V"
      },
      "source": [
        "#Wir bereiten unsere Testdaten gleich mit vor. Die brauchen wir, um unser Modell zu validieren.\n",
        "test_texte = [\"Ich bin total zufrieden.\",\n",
        "       \"Mann, ich bin SOWAS VON zufrieden!!!\",\n",
        "       \"Würde ich wieder kaufen.\",\n",
        "       \"Wirklich großer Mist.\",\n",
        "       \"Ist schon kaputt\",\n",
        "       \"Voll gut!\"]\n",
        "\n",
        "test_labels = [1,1,1,0,0,1]\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "data = list()\n",
        "data.extend(feedback_texte)\n",
        "data.extend(feedback_texte_advanced)\n",
        "data.extend(test_texte)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1rLuJ32w-0W"
      },
      "source": [
        "#Für ML-Experimente müssen wir Text i. d. R. in eine geeignete mathematische Repräsentation bringen.\n",
        "#Hier repräsentieren wir den Datensatz als Matrix von Tfidf-Werten.\n",
        "\n",
        "all_data = vectorizer.fit_transform(data)\n",
        "#Wir wollen lernen, sentiment labels (1=positiv, 0=negativ) vorherzusagen. Dafür trainieren wir mit bereits gelabelten Daten.\n",
        "#Sind die train_labels wirklich korrekt? Wie könnte man die Kundenmeinungen noch einordnen?\n",
        "train_labels = [1,1,0,0,1,0,1,1,1,1,1,0,0,0,0,0,0,0,1]\n",
        "\n",
        "#Wir splitten Trainings- und Testdaten.\n",
        "train_data = all_data[:len(feedback_texte)+len(feedback_texte_advanced)]\n",
        "test_data = all_data[len(feedback_texte)+len(feedback_texte_advanced):]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "igQWGPBaw-0W"
      },
      "source": [
        "#Wir trainieren ein Modell.\n",
        "#https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html\n",
        "\n",
        "nb = MultinomialNB()\n",
        "model = nb.fit(train_data, train_labels)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UmUFaZgxw-0W"
      },
      "source": [
        "#Wir testen das Modell, indem wir die Vorhersagen auf den Testdaten auswerten.\n",
        "\n",
        "predictions = model.predict(test_data)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TldDewq4w-0W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f77144ef-85d8-47ca-cb9a-56eb583536cc"
      },
      "source": [
        "for text, prediction in zip(test_texte, predictions):\n",
        "    print(text, prediction)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ich bin total zufrieden. 1\n",
            "Mann, ich bin SOWAS VON zufrieden!!! 1\n",
            "Würde ich wieder kaufen. 0\n",
            "Wirklich großer Mist. 0\n",
            "Ist schon kaputt 0\n",
            "Voll gut! 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w_p6op3rUrh3",
        "outputId": "60388ced-888d-481c-dd6e-4db4ef9d0fd6"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "accuracy = accuracy_score(predictions, test_labels)\n",
        "\n",
        "print(f'Unser Modell klassifiziert {accuracy*100} % der Sätze richtig. ')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unser Modell klassifiziert 66.66666666666666 % der Sätze richtig. \n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}